{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##Air Raid gaming bot\n",
    "Choose one of the games in OpenAI gym and make a bot that play it using GA.\n",
    "\n",
    "Beside the code, add a link to a video of your bot playing.\n",
    "##### Hint: There are many ways to do this, one of which is making a simple ANN and instead of using gradient decent use GA mutation and cross over to update your network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-02T02:25:48.114684Z",
     "end_time": "2023-05-02T02:25:52.743662Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "from typing import List\n",
    "\n",
    "#making bot for Open AI gym game using ANN and GA to update the weights of network\n",
    "import gym as gym\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from gym import Env\n",
    "from gym.spaces import Discrete, Box\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# !pip install gym[atari]\n",
    "# !pip install gym[accept-rom-license]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-02T02:25:52.742950Z",
     "end_time": "2023-05-02T02:25:52.763336Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# !pip install opencv-python"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\freid\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:31: UserWarning: \u001B[33mWARN: A Box observation space has an unconventional shape (neither an image, nor a 1D vector). We recommend flattening the observation to have only a 1D vector or use a custom policy to properly process the data. Actual observation shape: (250, 160)\u001B[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "(array([[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0],\n        ...,\n        [0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]], dtype=uint8),\n {'lives': 1, 'episode_frame_number': 8, 'frame_number': 16})"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make('ALE/AirRaid-v5', obs_type=\"grayscale\", # render_mode=\"human\",\n",
    "               frameskip=4)\n",
    "\n",
    "env.metadata['video.frames_per_second'] = 120\n",
    "env.reset()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-02T02:25:52.766316Z",
     "end_time": "2023-05-02T02:25:52.972062Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# CNN model for deciding what action to take according to observation\n",
    "# output = 0 -> noop\n",
    "# output = 1 -> fire\n",
    "# output = 2 -> right\n",
    "# output = 3 -> left\n",
    "# output = 4 -> rightfire\n",
    "# output = 5 -> leftfire\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(8, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(16, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(16, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D((2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(12, activation='relu'),\n",
    "    tf.keras.layers.Dense(6, activation='softmax')\n",
    "])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-02T02:25:52.977048Z",
     "end_time": "2023-05-02T02:25:53.059021Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "model.build(input_shape=(None, 70, 70, 1))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-02T02:25:53.050194Z",
     "end_time": "2023-05-02T02:25:53.208425Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 68, 68, 8)         80        \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 34, 34, 8)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 32, 32, 16)        1168      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 16, 16, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 14, 14, 16)        2320      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 7, 7, 16)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 12)                9420      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 6)                 78        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,066\n",
      "Trainable params: 13,066\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "number_of_weights = model.count_params()\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-02T02:25:53.219397Z",
     "end_time": "2023-05-02T02:25:53.299956Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# model.layers[7].get_weights()[0].shape, model.layers[7].get_weights()[1].shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-02T02:25:53.268502Z",
     "end_time": "2023-05-02T02:25:53.300952Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# LEARNING PROCESS"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "#range of values for weights\n",
    "# Initial range was [-1, 1].\n",
    "# After some testing and learning the problem,\n",
    "# I found that [0, 1] is better range, just to make learning faster.\n",
    "LOW = -1\n",
    "UP = 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-02T02:25:53.290979Z",
     "end_time": "2023-05-02T02:25:53.338099Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def create_weight() -> float:\n",
    "    return random.uniform(LOW, UP)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-02T02:25:53.317088Z",
     "end_time": "2023-05-02T02:25:53.339202Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def create_individual() -> List[float]:\n",
    "    return [create_weight() for _ in range(number_of_weights)]\n",
    "\n",
    "\n",
    "def create_population() -> List[List[float]]:\n",
    "    return [create_individual() for _ in range(population_size)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-02T02:25:53.328053Z",
     "end_time": "2023-05-02T02:25:53.345279Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def crossover(parent1: List[float], parent2: List[float]) -> (List[float], List[float]):\n",
    "    crossover_point = random.randint(0, number_of_weights - 1)\n",
    "    parent1 = parent1.copy()\n",
    "    parent2 = parent2.copy()\n",
    "    if random.random() < p_crossover:\n",
    "        child1 = parent1[:crossover_point] + parent2[crossover_point:]\n",
    "        child2 = parent2[:crossover_point] + parent1[crossover_point:]\n",
    "        return child1, child2\n",
    "    else:\n",
    "        return parent1, parent2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-02T02:25:53.340111Z",
     "end_time": "2023-05-02T02:25:53.354199Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def selection(population: List[List[float]]) -> (List[float], List[float]):\n",
    "    return random.choices(\n",
    "        population=population,\n",
    "        k=2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-02T02:25:53.372943Z",
     "end_time": "2023-05-02T02:25:53.412528Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def mutation(individual) -> List[float]:\n",
    "    for i in range(number_of_weights):\n",
    "        if random.random() < p_mutation:\n",
    "            individual[i] = create_weight()\n",
    "    return individual"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-02T02:25:53.385136Z",
     "end_time": "2023-05-02T02:25:53.417486Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# Fitness is equal to total reward in our case,\n",
    "# so to determine reward we need to play the game each time\n",
    "# actions are decided by NN\n",
    "def fitness(individual: List[float]) -> float:\n",
    "    inserted = 0\n",
    "    for i, layer in enumerate(model.layers):\n",
    "        if i in [1, 3, 5, 6]:\n",
    "            continue\n",
    "\n",
    "        layer_weights_shape = layer.get_weights()[0].shape\n",
    "        layer_biases_shape = layer.get_weights()[1].shape\n",
    "\n",
    "        # total number of weights in layer = product of all dimensions\n",
    "        total_n_weights = np.prod(layer_weights_shape)\n",
    "        total_n_biases = np.prod(layer_biases_shape)\n",
    "\n",
    "        # get weights and biases from individual\n",
    "        layer_weights = np.array(individual[inserted:inserted + total_n_weights]).reshape(layer_weights_shape)\n",
    "        layer_biases = np.array(\n",
    "            individual[inserted + total_n_weights:inserted + total_n_weights + total_n_biases]).reshape(\n",
    "            layer_biases_shape)\n",
    "\n",
    "        # set weights and biases in model\n",
    "        layer.set_weights([layer_weights, layer_biases])\n",
    "\n",
    "        # update inserted\n",
    "        inserted += total_n_weights + total_n_biases\n",
    "    observation = env.reset()[0]\n",
    "    done = False\n",
    "    action_count = 0\n",
    "    total_reward = 0\n",
    "    while not done and action_count < 100 and total_reward < 2000:\n",
    "        observation = observation[35:170, 20:]\n",
    "        observation = cv2.resize(observation, dsize=(70, 70), interpolation=cv2.INTER_CUBIC)\n",
    "        action = model.predict(np.array([observation]), verbose=0)\n",
    "\n",
    "        # action = number with the highest probability\n",
    "        action = np.argmax(action)\n",
    "        #print(action)\n",
    "        #print(env.step(action))\n",
    "        observation, reward, truncted, terminated, info = env.step(action)\n",
    "        action_count += 1\n",
    "        done = terminated or truncted\n",
    "        total_reward += reward\n",
    "\n",
    "    return total_reward"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-02T02:25:53.420450Z",
     "end_time": "2023-05-02T02:25:53.450372Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "import copy\n",
    "import time\n",
    "def save_best_model(individual):\n",
    "    inserted = 0\n",
    "    for i, layer in enumerate(model.layers):\n",
    "        if i in [1, 3, 5, 6]:\n",
    "            continue\n",
    "\n",
    "        layer_weights_shape = layer.get_weights()[0].shape\n",
    "        layer_biases_shape = layer.get_weights()[1].shape\n",
    "\n",
    "        # total number of weights in layer = product of all dimensions\n",
    "        total_n_weights = np.prod(layer_weights_shape)\n",
    "        total_n_biases = np.prod(layer_biases_shape)\n",
    "\n",
    "        # get weights and biases from individual\n",
    "        layer_weights = np.array(individual[inserted:inserted + total_n_weights]).reshape(layer_weights_shape)\n",
    "        layer_biases = np.array(\n",
    "            individual[inserted + total_n_weights:inserted + total_n_weights + total_n_biases]).reshape(\n",
    "            layer_biases_shape)\n",
    "\n",
    "        # set weights and biases in model\n",
    "        layer.set_weights([layer_weights, layer_biases])\n",
    "\n",
    "        inserted += total_n_weights + total_n_biases\n",
    "    model.save('best_model')\n",
    "def run_ga(pop_size: int, gen_limit: int, p_crossover: float, p_mutation: float) -> List[float]:\n",
    "    start_time = time.time()\n",
    "    print(\"Creating initial population...\")\n",
    "    population_main = create_population()\n",
    "    print(\"Evaluating initial population...\")\n",
    "    population_main.sort(key=fitness, reverse=True)\n",
    "    print(\"Main population sorted.\")\n",
    "    print(f\"Time execution of population initialization:\",\"%s s\" % (time.time() - start_time))\n",
    "    print(f\"Best fitness, GEN INIT : {fitness(population_main[0])}\")\n",
    "    for generation in range(gen_limit):\n",
    "        start_time = time.time()\n",
    "        population_next = copy.deepcopy(population_main[:2])\n",
    "        print(f\"Saving the best model in the generation {generation}...\")\n",
    "        save_best_model(population_main[0])\n",
    "        print(\"Creating next population...\")\n",
    "        for _ in range(pop_size // 2 - 1):\n",
    "            parent1, parent2 = selection(population_main)\n",
    "            child1, child2 = crossover(parent1, parent2)\n",
    "            child1 = mutation(child1)\n",
    "            child2 = mutation(child2)\n",
    "            population_next.append(child1)\n",
    "            population_next.append(child2)\n",
    "        population_main = copy.deepcopy(population_next)\n",
    "        print(\"Evaluating next population...\")\n",
    "        population_main.sort(key=fitness, reverse=True)\n",
    "        print(\"Next population sorted.\")\n",
    "        best_f = fitness(population_main[0])\n",
    "        if best_f == 500:\n",
    "            print(f\"Best fitness, GEN {generation} : {best_f}\")\n",
    "            return population_main[0]\n",
    "        else:\n",
    "            print(f\"Best fitness, GEN {generation} : {best_f}\")\n",
    "        print(f\"Time execution of gen {generation}:\",\"%s s\" % (time.time() - start_time))\n",
    "        print(\"--------------------------------\")\n",
    "\n",
    "    population_main.sort(key=fitness, reverse=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating initial population...\n",
      "Evaluating initial population...\n",
      "Main population sorted.\n",
      "Time execution of population initialization: 76.0111894607544 s\n",
      "Best fitness, GEN INIT : 250.0\n",
      "Saving the best model in the generation 0...\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating next population...\n",
      "Evaluating next population...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [20], line 5\u001B[0m\n\u001B[0;32m      3\u001B[0m p_crossover \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.7\u001B[39m\n\u001B[0;32m      4\u001B[0m p_mutation \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.6\u001B[39m\n\u001B[1;32m----> 5\u001B[0m best_weights \u001B[38;5;241m=\u001B[39m \u001B[43mrun_ga\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpop_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpopulation_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgen_limit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mp_crossover\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mp_crossover\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mp_mutation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mp_mutation\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn [19], line 52\u001B[0m, in \u001B[0;36mrun_ga\u001B[1;34m(pop_size, gen_limit, p_crossover, p_mutation)\u001B[0m\n\u001B[0;32m     50\u001B[0m population_main \u001B[38;5;241m=\u001B[39m copy\u001B[38;5;241m.\u001B[39mdeepcopy(population_next)\n\u001B[0;32m     51\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEvaluating next population...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 52\u001B[0m \u001B[43mpopulation_main\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msort\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfitness\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreverse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m     53\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNext population sorted.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     54\u001B[0m best_f \u001B[38;5;241m=\u001B[39m fitness(population_main[\u001B[38;5;241m0\u001B[39m])\n",
      "Cell \u001B[1;32mIn [16], line 35\u001B[0m, in \u001B[0;36mfitness\u001B[1;34m(individual)\u001B[0m\n\u001B[0;32m     33\u001B[0m observation \u001B[38;5;241m=\u001B[39m observation[\u001B[38;5;241m35\u001B[39m:\u001B[38;5;241m170\u001B[39m, \u001B[38;5;241m20\u001B[39m:]\n\u001B[0;32m     34\u001B[0m observation \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mresize(observation, dsize\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m70\u001B[39m, \u001B[38;5;241m70\u001B[39m), interpolation\u001B[38;5;241m=\u001B[39mcv2\u001B[38;5;241m.\u001B[39mINTER_CUBIC)\n\u001B[1;32m---> 35\u001B[0m action \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43marray\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mobservation\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     37\u001B[0m \u001B[38;5;66;03m# action = number with the highest probability\u001B[39;00m\n\u001B[0;32m     38\u001B[0m action \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39margmax(action)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py:2349\u001B[0m, in \u001B[0;36mModel.predict\u001B[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   2340\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m:\n\u001B[0;32m   2341\u001B[0m         warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m   2342\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUsing Model.predict with MultiWorkerMirroredStrategy \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   2343\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mor TPUStrategy and AutoShardPolicy.FILE might lead to \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   2346\u001B[0m             stacklevel\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m,\n\u001B[0;32m   2347\u001B[0m         )\n\u001B[1;32m-> 2349\u001B[0m data_handler \u001B[38;5;241m=\u001B[39m \u001B[43mdata_adapter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_data_handler\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2350\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2351\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2352\u001B[0m \u001B[43m    \u001B[49m\u001B[43msteps_per_epoch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msteps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2353\u001B[0m \u001B[43m    \u001B[49m\u001B[43minitial_epoch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2354\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2355\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_queue_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_queue_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2356\u001B[0m \u001B[43m    \u001B[49m\u001B[43mworkers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mworkers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2357\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_multiprocessing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_multiprocessing\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2358\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2359\u001B[0m \u001B[43m    \u001B[49m\u001B[43msteps_per_execution\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_steps_per_execution\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2360\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2362\u001B[0m \u001B[38;5;66;03m# Container that configures and calls `tf.keras.Callback`s.\u001B[39;00m\n\u001B[0;32m   2363\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(callbacks, callbacks_module\u001B[38;5;241m.\u001B[39mCallbackList):\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\data_adapter.py:1583\u001B[0m, in \u001B[0;36mget_data_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m   1581\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m\"\u001B[39m], \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_cluster_coordinator\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m   1582\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _ClusterCoordinatorDataHandler(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m-> 1583\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m DataHandler(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\data_adapter.py:1260\u001B[0m, in \u001B[0;36mDataHandler.__init__\u001B[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001B[0m\n\u001B[0;32m   1257\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_steps_per_execution \u001B[38;5;241m=\u001B[39m steps_per_execution\n\u001B[0;32m   1259\u001B[0m adapter_cls \u001B[38;5;241m=\u001B[39m select_data_adapter(x, y)\n\u001B[1;32m-> 1260\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_adapter \u001B[38;5;241m=\u001B[39m \u001B[43madapter_cls\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1261\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1262\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1263\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1264\u001B[0m \u001B[43m    \u001B[49m\u001B[43msteps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msteps_per_epoch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1265\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[43minitial_epoch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1266\u001B[0m \u001B[43m    \u001B[49m\u001B[43msample_weights\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1267\u001B[0m \u001B[43m    \u001B[49m\u001B[43mshuffle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mshuffle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1268\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_queue_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_queue_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1269\u001B[0m \u001B[43m    \u001B[49m\u001B[43mworkers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mworkers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1270\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_multiprocessing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_multiprocessing\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1271\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdistribution_strategy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdistribute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_strategy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1272\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1273\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1275\u001B[0m strategy \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mdistribute\u001B[38;5;241m.\u001B[39mget_strategy()\n\u001B[0;32m   1277\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_current_step \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\data_adapter.py:289\u001B[0m, in \u001B[0;36mTensorLikeDataAdapter.__init__\u001B[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001B[0m\n\u001B[0;32m    277\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_shuffle \u001B[38;5;241m=\u001B[39m shuffle\n\u001B[0;32m    278\u001B[0m \u001B[38;5;66;03m# Vectorized version of shuffle.\u001B[39;00m\n\u001B[0;32m    279\u001B[0m \u001B[38;5;66;03m# This is a performance improvement over using `from_tensor_slices`.\u001B[39;00m\n\u001B[0;32m    280\u001B[0m \u001B[38;5;66;03m# The indices of the data are shuffled and batched, and these indices\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    286\u001B[0m \u001B[38;5;66;03m# 4. optimized permutation batching\u001B[39;00m\n\u001B[0;32m    287\u001B[0m \u001B[38;5;66;03m# 5. disabled static optimizations\u001B[39;00m\n\u001B[1;32m--> 289\u001B[0m indices_dataset \u001B[38;5;241m=\u001B[39m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mDataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrange\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    290\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m shuffle \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbatch\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    291\u001B[0m     indices_dataset \u001B[38;5;241m=\u001B[39m indices_dataset\u001B[38;5;241m.\u001B[39mrepeat(epochs)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:1015\u001B[0m, in \u001B[0;36mDatasetV2.range\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m   1011\u001B[0m \u001B[38;5;66;03m# Loaded lazily due to a circular dependency (dataset_ops -> range_op ->\u001B[39;00m\n\u001B[0;32m   1012\u001B[0m \u001B[38;5;66;03m# -> dataset_ops).\u001B[39;00m\n\u001B[0;32m   1013\u001B[0m \u001B[38;5;66;03m# pylint: disable=g-import-not-at-top,protected-access\u001B[39;00m\n\u001B[0;32m   1014\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mops\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m range_op\n\u001B[1;32m-> 1015\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m range_op\u001B[38;5;241m.\u001B[39m_range(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\data\\ops\\range_op.py:25\u001B[0m, in \u001B[0;36m_range\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_range\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):  \u001B[38;5;66;03m# pylint: disable=unused-private-name\u001B[39;00m\n\u001B[1;32m---> 25\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m _RangeDataset(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\data\\ops\\range_op.py:35\u001B[0m, in \u001B[0;36m_RangeDataset.__init__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m     33\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_parse_args(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     34\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_structure \u001B[38;5;241m=\u001B[39m tensor_spec\u001B[38;5;241m.\u001B[39mTensorSpec([], \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output_type)\n\u001B[1;32m---> 35\u001B[0m variant_tensor \u001B[38;5;241m=\u001B[39m gen_dataset_ops\u001B[38;5;241m.\u001B[39mrange_dataset(\n\u001B[0;32m     36\u001B[0m     start\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_start,\n\u001B[0;32m     37\u001B[0m     stop\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stop,\n\u001B[0;32m     38\u001B[0m     step\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_step,\n\u001B[0;32m     39\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_common_args)\n\u001B[0;32m     40\u001B[0m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(variant_tensor)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:6209\u001B[0m, in \u001B[0;36mrange_dataset\u001B[1;34m(start, stop, step, output_types, output_shapes, metadata, replicate_on_split, name)\u001B[0m\n\u001B[0;32m   6207\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m tld\u001B[38;5;241m.\u001B[39mis_eager:\n\u001B[0;32m   6208\u001B[0m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 6209\u001B[0m     _result \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_FastPathExecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   6210\u001B[0m \u001B[43m      \u001B[49m\u001B[43m_ctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mRangeDataset\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstart\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstep\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43moutput_types\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   6211\u001B[0m \u001B[43m      \u001B[49m\u001B[43moutput_types\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43moutput_shapes\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_shapes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmetadata\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetadata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   6212\u001B[0m \u001B[43m      \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mreplicate_on_split\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreplicate_on_split\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   6213\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _result\n\u001B[0;32m   6214\u001B[0m   \u001B[38;5;28;01mexcept\u001B[39;00m _core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "#start learning and rendering the game\n",
    "population_size = 10\n",
    "p_crossover = 0.7\n",
    "p_mutation = 0.6\n",
    "best_weights = run_ga(pop_size=population_size, gen_limit=10,\n",
    "                      p_crossover=p_crossover, p_mutation=p_mutation)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-02T02:25:53.449376Z",
     "end_time": "2023-05-02T02:41:36.268263Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#show the game with best model\n",
    "model = tf.keras.models.load_model(\"best_model\")\n",
    "model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-02T02:41:36.286729Z",
     "end_time": "2023-05-02T02:41:36.323482Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "env.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-02T02:41:36.341120Z",
     "end_time": "2023-05-02T02:41:36.395839Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
